{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "조롱글헤드라인",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "bVYfJ0aTdPBn",
        "outputId": "9cc925d5-141e-4c3d-8c5e-3ae4dc41b373",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#https://teddylee777.github.io/tensorflow/news-sarcasm\n",
        "!pip install tensorflow==2.1.0\n",
        "import json\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import urllib\n",
        "\n",
        "from tensorflow.keras.layers import Embedding, Bidirectional, LSTM, Dense, Flatten\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "url = 'https://storage.googleapis.com/download.tensorflow.org/data/sarcasm.json'\n",
        "urllib.request.urlretrieve(url, 'sarcasm.json')\n",
        "\n",
        "vocab_size = 1000\n",
        "embedding_dim = 16\n",
        "max_length = 120\n",
        "trunc_type='post'\n",
        "padding_type='post'\n",
        "oov_tok = \"<OOV>\"\n",
        "training_size = 20000\n",
        "batch_size = 256\n",
        "sentences = []\n",
        "labels = []\n",
        "\n",
        "with open('sarcasm.json', 'r') as f:\n",
        "    datastore = json.load(f)\n",
        "\n",
        "for item in datastore:\n",
        "    sentences.append(item['headline'])\n",
        "    labels.append(item['is_sarcastic'])\n",
        "\n",
        "\n",
        "tokenizer = Tokenizer(num_words=vocab_size, oov_token=oov_tok) #빈도수가 높은 단어 top 1000개 \n",
        "tokenizer.fit_on_texts(sentences)\n",
        "\n",
        "sequences = tokenizer.texts_to_sequences(sentences) #텍스트 > 숫자 \n",
        "\n",
        "padded = pad_sequences(sequences, truncating=trunc_type, padding=padding_type, maxlen=max_length) #(,120)으로 설정\n",
        "\n",
        "#train, valid 분리\n",
        "train_padded = padded[:training_size]\n",
        "train_labels = labels[:training_size]\n",
        "\n",
        "validation_padded = padded[training_size:]\n",
        "validation_labels = labels[training_size:]\n",
        "\n",
        "train_labels = np.array(train_labels)\n",
        "validation_labels = np.array(validation_labels)\n",
        "\n",
        "model = Sequential([\n",
        "    Embedding(vocab_size, embedding_dim, input_length=max_length), #16차원으로축소\n",
        "    Bidirectional(tf.keras.layers.LSTM(64, return_sequences=True)),\n",
        "    Bidirectional(tf.keras.layers.LSTM(64)),\n",
        "    Flatten(),\n",
        "    Dense(16, activation='relu'),\n",
        "    Dense(32, activation='relu'),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "                loss='binary_crossentropy', \n",
        "                metrics=['accuracy'])\n",
        "\n",
        "checkpoint_path = 'my_checkpoint.ckpt'\n",
        "sarcasm_checkpoint = ModelCheckpoint(checkpoint_path, \n",
        "                                                save_weights_only=True, \n",
        "                                                save_best_only=True, \n",
        "                                                monitor='val_loss',\n",
        "                                                verbose=1)\n",
        "\n",
        "\n",
        "\n",
        "hist = model.fit(train_padded, train_labels, \n",
        "            validation_data=(validation_padded, validation_labels),\n",
        "            callbacks=[sarcasm_checkpoint],batch_size=batch_size,\n",
        "            epochs=10)\n",
        "\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow==2.1.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/85/d4/c0cd1057b331bc38b65478302114194bd8e1b9c2bbc06e300935c0e93d90/tensorflow-2.1.0-cp36-cp36m-manylinux2010_x86_64.whl (421.8MB)\n",
            "\u001b[K     |████████████████████████████████| 421.8MB 27kB/s \n",
            "\u001b[?25hRequirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (1.32.0)\n",
            "Collecting tensorboard<2.2.0,>=2.1.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d9/41/bbf49b61370e4f4d245d4c6051dfb6db80cec672605c91b1652ac8cc3d38/tensorboard-2.1.1-py3-none-any.whl (3.8MB)\n",
            "\u001b[K     |████████████████████████████████| 3.9MB 48.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (3.12.4)\n",
            "Collecting tensorflow-estimator<2.2.0,>=2.1.0rc0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/18/90/b77c328a1304437ab1310b463e533fa7689f4bfc41549593056d812fab8e/tensorflow_estimator-2.1.0-py2.py3-none-any.whl (448kB)\n",
            "\u001b[K     |████████████████████████████████| 450kB 40.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (0.8.1)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (1.1.2)\n",
            "Requirement already satisfied: scipy==1.4.1; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (1.4.1)\n",
            "Collecting keras-applications>=1.0.8\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/e3/19762fdfc62877ae9102edf6342d71b28fbfd9dea3d2f96a882ce099b03f/Keras_Applications-1.0.8-py3-none-any.whl (50kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 7.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (3.3.0)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (1.18.5)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (0.2.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (1.12.1)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (0.10.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (1.15.0)\n",
            "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (0.35.1)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (1.1.0)\n",
            "Collecting gast==0.2.2\n",
            "  Downloading https://files.pythonhosted.org/packages/4e/35/11749bf99b2d4e3cceb4d55ca22590b0d7c2c62b9de38ac4a4a7f4687421/gast-0.2.2.tar.gz\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (2.23.0)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (1.17.2)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (50.3.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (0.4.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (3.2.2)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow==2.1.0) (2.10.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (2020.6.20)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (4.1.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (4.6)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (1.7.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.6/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (3.1.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (3.1.0)\n",
            "Building wheels for collected packages: gast\n",
            "  Building wheel for gast (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gast: filename=gast-0.2.2-cp36-none-any.whl size=7542 sha256=65e5b1b98ad949908ec86a6ac1944f99c9eef2f6491606136ce0c7da67eeb322\n",
            "  Stored in directory: /root/.cache/pip/wheels/5c/2e/7e/a1d4d4fcebe6c381f378ce7743a3ced3699feb89bcfbdadadd\n",
            "Successfully built gast\n",
            "\u001b[31mERROR: tensorflow-probability 0.11.0 has requirement gast>=0.3.2, but you'll have gast 0.2.2 which is incompatible.\u001b[0m\n",
            "Installing collected packages: tensorboard, tensorflow-estimator, keras-applications, gast, tensorflow\n",
            "  Found existing installation: tensorboard 2.3.0\n",
            "    Uninstalling tensorboard-2.3.0:\n",
            "      Successfully uninstalled tensorboard-2.3.0\n",
            "  Found existing installation: tensorflow-estimator 2.3.0\n",
            "    Uninstalling tensorflow-estimator-2.3.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.3.0\n",
            "  Found existing installation: gast 0.3.3\n",
            "    Uninstalling gast-0.3.3:\n",
            "      Successfully uninstalled gast-0.3.3\n",
            "  Found existing installation: tensorflow 2.3.0\n",
            "    Uninstalling tensorflow-2.3.0:\n",
            "      Successfully uninstalled tensorflow-2.3.0\n",
            "Successfully installed gast-0.2.2 keras-applications-1.0.8 tensorboard-2.1.1 tensorflow-2.1.0 tensorflow-estimator-2.1.0\n",
            "Train on 20000 samples, validate on 6709 samples\n",
            "Epoch 1/10\n",
            "19712/20000 [============================>.] - ETA: 0s - loss: 0.6117 - accuracy: 0.6350\n",
            "Epoch 00001: val_loss improved from inf to 0.42065, saving model to my_checkpoint.ckpt\n",
            "20000/20000 [==============================] - 14s 712us/sample - loss: 0.6086 - accuracy: 0.6375 - val_loss: 0.4206 - val_accuracy: 0.8064\n",
            "Epoch 2/10\n",
            "19712/20000 [============================>.] - ETA: 0s - loss: 0.3781 - accuracy: 0.8270\n",
            "Epoch 00002: val_loss improved from 0.42065 to 0.38581, saving model to my_checkpoint.ckpt\n",
            "20000/20000 [==============================] - 3s 153us/sample - loss: 0.3788 - accuracy: 0.8262 - val_loss: 0.3858 - val_accuracy: 0.8214\n",
            "Epoch 3/10\n",
            "19712/20000 [============================>.] - ETA: 0s - loss: 0.3508 - accuracy: 0.8407\n",
            "Epoch 00003: val_loss improved from 0.38581 to 0.37671, saving model to my_checkpoint.ckpt\n",
            "20000/20000 [==============================] - 3s 152us/sample - loss: 0.3505 - accuracy: 0.8408 - val_loss: 0.3767 - val_accuracy: 0.8304\n",
            "Epoch 4/10\n",
            "19712/20000 [============================>.] - ETA: 0s - loss: 0.3407 - accuracy: 0.8474\n",
            "Epoch 00004: val_loss did not improve from 0.37671\n",
            "20000/20000 [==============================] - 3s 150us/sample - loss: 0.3400 - accuracy: 0.8475 - val_loss: 0.3927 - val_accuracy: 0.8287\n",
            "Epoch 5/10\n",
            "19968/20000 [============================>.] - ETA: 0s - loss: 0.3259 - accuracy: 0.8548\n",
            "Epoch 00005: val_loss did not improve from 0.37671\n",
            "20000/20000 [==============================] - 3s 155us/sample - loss: 0.3258 - accuracy: 0.8547 - val_loss: 0.3786 - val_accuracy: 0.8284\n",
            "Epoch 6/10\n",
            "19712/20000 [============================>.] - ETA: 0s - loss: 0.3110 - accuracy: 0.8628\n",
            "Epoch 00006: val_loss improved from 0.37671 to 0.37322, saving model to my_checkpoint.ckpt\n",
            "20000/20000 [==============================] - 3s 152us/sample - loss: 0.3112 - accuracy: 0.8627 - val_loss: 0.3732 - val_accuracy: 0.8374\n",
            "Epoch 7/10\n",
            "19712/20000 [============================>.] - ETA: 0s - loss: 0.2991 - accuracy: 0.8673\n",
            "Epoch 00007: val_loss did not improve from 0.37322\n",
            "20000/20000 [==============================] - 3s 153us/sample - loss: 0.2994 - accuracy: 0.8672 - val_loss: 0.3788 - val_accuracy: 0.8328\n",
            "Epoch 8/10\n",
            "19712/20000 [============================>.] - ETA: 0s - loss: 0.2952 - accuracy: 0.8711\n",
            "Epoch 00008: val_loss did not improve from 0.37322\n",
            "20000/20000 [==============================] - 3s 151us/sample - loss: 0.2953 - accuracy: 0.8711 - val_loss: 0.3825 - val_accuracy: 0.8338\n",
            "Epoch 9/10\n",
            "19712/20000 [============================>.] - ETA: 0s - loss: 0.2889 - accuracy: 0.8738\n",
            "Epoch 00009: val_loss did not improve from 0.37322\n",
            "20000/20000 [==============================] - 3s 150us/sample - loss: 0.2899 - accuracy: 0.8733 - val_loss: 0.3982 - val_accuracy: 0.8293\n",
            "Epoch 10/10\n",
            "19712/20000 [============================>.] - ETA: 0s - loss: 0.2843 - accuracy: 0.8730\n",
            "Epoch 00010: val_loss did not improve from 0.37322\n",
            "20000/20000 [==============================] - 3s 151us/sample - loss: 0.2844 - accuracy: 0.8730 - val_loss: 0.3966 - val_accuracy: 0.8286\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}