{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## * 딥러닝 기본 요소\n",
    "\n",
    "### 완전연결 계층\n",
    "\n",
    "완전연결 네트워크는 입력 목록을 출력 목록으로 변환합니다. 모든 입력값이 모든 출력값에 영향을 줄 수 있기 때문에 이러한 변환을 완전연결이라고 합니다.  \n",
    "완전연결 계층은 비교적 적은 입력에 대해서도 많은 학습 매개변수가 필요하지만, 입력에 정해진 구조가 없다는 가정이 큰 이점입니다.\n",
    "\n",
    "### 합성곱 계층\n",
    "\n",
    "합성곱 네트워크는 특별한 공간 구조를 취하는 입력을 가정합니다. 특히 공간상 서로 가까이 있는 입력은 의미적으로 관련이 있다고 가정합니다.  \n",
    "이러한 가정은 이미지에 가장 적합한데, 이는 서로 가까이 있는 픽셀은 의미적으로 연결되어 있을 가능성이 크기 때문입니다.  \n",
    "\n",
    "따라서 합성곱 계층은 이미지 처리를 위한 딥 아키텍처에 폭 넓게 사용됩니다.\n",
    "\n",
    "### 순환 신경망 계층\n",
    "\n",
    "순환 신경망(RNN) 계층은 입력 시퀀스로 신경망을 학습시키는 기본 요소입니다. 이 계층은 데이터를 학습할 수 있는 정의된 갱신 규칙에 따라 입력이 단계적으로 전개된다고 가정합니다.  \n",
    "이 갱신 규칙은 이전에 발생한 모든 상태를 반영하므로 시퀀스에서 다음 상태를 에측할 수 있게 됩니다.\n",
    "\n",
    "RNN은 언어 모델링과 같은 작업에 매우 유용합니다.\n",
    "\n",
    "### 장단기 기억 셀\n",
    "\n",
    "RNN 계층은 이론적으로 임의의 시퀀스 갱신 규칙을 학습할 수 있습니다. 하지만 실제로 먼 과거의 영향은 학습할 수 없습니다.  \n",
    "정교한 언어 모델링을 위해서는 먼 거리의 영향이 매우 중요한데 복잡한 문장은 멀리 떨어진 단어들의 관계에 따라 의미가 달라질 수 있기 때문입니다.  \n",
    "장단기 기억(LSTM) 셀은 RNN 게층을 변형한 것으로 먼 과거에서 온 신호를 현재로 전달될 수 있도록 해줍니다.\n",
    "\n",
    "## * 딥러닝 아키텍처\n",
    "\n",
    "### LeNet\n",
    "\n",
    "LeNet 아키텍처는 최초로 널리 알려진 '심층' 합성곱 아키텍처로 1988년 소개되어 문서용 광학 문자 인식(OCR)에 사용되었습니다.\n",
    "\n",
    "### AlexNet\n",
    "\n",
    "ILSVRC 는 시각 인식 시스템의 성능 개선을 겨루는 대회인데, 처음 2년동안은 HOG와 SIFT 피처 같은 수동으로 시각적 피처를 추출하는 전통적 머신러닝 시스템이 우세했습니다.  \n",
    "2012년에 GPU를 사용하며 LeNet 아키텍처를 변형한 AlexNet 아키텍처가 오류율을 경쟁팀의 절반 수준으로 낮추며 압도적인 승리를 거두었습니다.\n",
    "\n",
    "### ResNet\n",
    "\n",
    "합성곱 아키텍처는 2012년부터 꾸준히 ILSVRC에서 우승을 차지했는데, 회를 거듭할 수록 우승작의 아키텍처의 깊이가 깊어지고 복잡해졌습니다.  \n",
    "매우 깊은 딥러닝은 신호가 네트워크를 진행하면서 점차 감소하고 학습이 약화되는 '기울기가 소실되는 문제'를 발생시켰습니다.  \n",
    "따라서 딥러닝에서 유효한 네트워크 깊이에 한계가 발생했습니다.\n",
    "\n",
    "이러한 감쇠를 제어하기 위해 ResNet은 우회 연결을 도입했습니다. 이러한 연결을 통해 깊은 계층의 네트워크에도 신경망이 효과적으로 학습할 수 있게되었습니다.\n",
    "\n",
    "### 신경 캡셔닝 모델\n",
    "\n",
    "신경 캡셔닝 시스템은 자동으로 이미지에 캡션을 생성하는 시스템입니다. 이미지에서 정보를 추출하는 합성곱 신경망과 이미지에 대한 설명문을 생성하는 LSTM 계층을 결합하여\n",
    "이미지에 캡션을 생성합니다. \n",
    "\n",
    "전체 시스템은 종단간 학습을 합니다. 즉 주어진 이미지에 대한 설명문을 만들기 위해 합성곱 신경망과 LSTM 네트워크는 함께 학습합니다.  \n",
    "이 종단간 학습은 오늘날의 딥러닝 시스템을 강화시킨 핵심 혁신 중 하나인데 이는 입력값에 대한 복잡한 전처리 과정의 필요성을 줄여주었기 때문입니다.  \n",
    "\n",
    "### 구글 신경망 기계번역\n",
    "\n",
    "구글 신경망 기계번역(GNMT) 시스템은 종단간 학습 패러다임을 사용한 번역 시스템으로 출발어를 문장 단위로 가져와 도착어로 번역합니다.\n",
    "최종 아키텍처는 인간과 기계번역 간의 차이를 최대 60%까지 줄이며 기계번역에 획기적인 발전을 가져왔습니다.\n",
    "\n",
    "### 원샷 모델\n",
    "\n",
    "일반적으로 대부분의 딥러닝 기술은 의미 있는 행동을 학습하기 위해 매우 많은 양의 데이터를 필요로 합니다.  \n",
    "하지만 인지과학의 많은 연구를 보면 인간은 단지 몇 가지 예시로도 복잡한 개념을 배울 수 있다고 합니다.\n",
    "\n",
    "최근 딥러닝의 발전은 이와 유사한 학습 성과를 낼 수 있는 아키텍처를 만들기 시작했습니다. 그러한 모델이 원샷 아키텍처 입니다.\n",
    "\n",
    "### 알파고\n",
    "\n",
    "구글 딥마인드 알파고는 심층 가치망과 심층 정책망을 사용합니다. 가치망은 바둑판 위치의 가치를 추정합니다. 가치망은 게임 결과를 학습하여 이러한 예측의 어려움을 해결합니다.  \n",
    "반면 정책망은 주어진 현재 상태에서 최선의 다음 수를 추정합니다. 이 두가지 기술을 몬테카를로 트리 탐색과 결합하여 바둑판에서 큰 분기 계수를 극복할 수 있었습니다.\n",
    "\n",
    "### 생성적 적대 신경망\n",
    "\n",
    "생성적 적대 신경망은 생성자와 적수라는 두 개의 신경망이 서로 경쟁하는 것을 이용한 새로운 형태의 딥 네트워크입니다. 생성자는 학습 데이터 분포에서 표본을 추출하려고 합니다.  \n",
    "판별자는 생성자가 만든 표본을 실제 데이터에서 추출한 표본과 구분하려 합니다. GAN의 '적대적' 학습은 다른 기술보다 훨씬 충실도가 높은 이미지 표본을 생성할 수 있으며  \n",
    "한정된 데이터로 효과적인 판별자를 학습하는데 유용합니다.\n",
    "\n",
    "### 신경 튜링머신\n",
    "\n",
    "지금까지의 딥러닝 시스템은 적용 범위가 한정된 복잡한 함수를 학습합니다. 하지만 정렬, 덧셈, 곱셈과 같은 일반적인 알고리즘 개념을 학습하는 딥 아키텍처를 만들 수도 있지 않을까요?  \n",
    "신경 튜링머신(NTM)은 임의의 알고리즘을 학습할 수 있는 딥러닝 아키텍처를 만든 최초의 시도입니다. 이 아키텍처는 LSTM과 같은 시스템에 외부 메모리 뱅크를 추가하여 딥 아키텍처가\n",
    "더 복잡한 함수를 계산할 수 있도록 스크래치 공간을 사용하게 합니다.\n",
    "\n",
    "## * 딥러닝 프레임워크\n",
    "\n",
    "### 텐서플로의 한계\n",
    "\n",
    "현재 텐서플로의 주요 약점 중 하나는 새로운 딥러닝 아키텍처를 구축하는 게 비교적 느리다는 것입니다. 결과적으로 텐서플로를 사용하여 구조를 동적으로 변경하는 정교한 딥 아키텍처를 구축하는 것은 편리하지 않습니다.\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}