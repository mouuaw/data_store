{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.3-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python37364bitbaseconda3e8d1efd23e942ffb39a1c2f774bdc3f",
   "display_name": "Python 3.7.3 64-bit ('base': conda)"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bayesian optimization 설명\n",
    "# http://research.sualab.com/introduction/practice/2019/02/19/bayesian-optimization-overview-1.html\n",
    "\n",
    "# parameter 설명\n",
    "# http://machinelearningkorea.com/2019/09/29/lightgbm-%ED%8C%8C%EB%9D%BC%EB%AF%B8%ED%84%B0/\n",
    "\n",
    "# 자료가 좀 있는듯\n",
    "# http://machinelearningkorea.com/\n",
    "\n",
    "## classification?\n",
    "# https://data-newbie.tistory.com/160\n",
    "# https://www.kaggle.com/sz8416/simple-bayesian-optimization-for-lightgbm\n",
    "\n",
    "# regression\n",
    "# https://www.kaggle.com/chocozzz/bayesian-optimization-for-lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.stats import chi2_contingency\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from bayes_opt import BayesianOptimization\n",
    "\n",
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('../data/train.csv', index_col='id')\n",
    "test = pd.read_csv('../data/test.csv', index_col='id')\n",
    "submission = pd.read_csv('../data/sample_submission.csv', index_col='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['X00', 'X01', 'X02', 'X03', 'X05', 'X06', 'X07', 'X08', 'X09', 'X10', 'X11', 'X12', 'X13', 'X15', 'X17', 'X18', 'X20', 'X21', 'X22', 'X23', 'X24', 'X25', 'X26', 'X27', 'X28', 'X29', 'X30', 'X31', 'X32', 'X33', 'X34', 'X35', 'X37', 'X38', 'X39']\n",
    "\n",
    "trainNotNull = train[train['Y18'].isnull()]\n",
    "\n",
    "## perm 작업을 하기전에 model fit을 수행함\n",
    "X = train[features]\n",
    "y = train['Y00']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "\n",
    "params = {\n",
    "            \"objective\" : \"regression\", \"bagging_fraction\" : 0.8, \"bagging_freq\": 1,\n",
    "            \"min_child_samples\": 20, \"reg_alpha\": 1, \"reg_lambda\": 1,\"boosting\": \"rf\",\n",
    "            \"learning_rate\" : 0.01, \"subsample\" : 0.8, \"colsample_bytree\" : 0.8, \"verbosity\": -1, \"metric\" : 'rmse'\n",
    "        }\n",
    "train_data = lgb.Dataset(data=X, label=y, categorical_feature = list(X.columns),free_raw_data=False)\n",
    "\n",
    "# Perform the cross-validation with given paramaters \n",
    "# https://lightgbm.readthedocs.io/en/latest/pythonapi/lightgbm.cv.html    \n",
    "cv_result = lgb.cv(params, train_data, nfold=5, seed=0, verbose_eval =200,stratified=False,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([-7.33838456, -6.82699482, -6.64162526, -6.56420956, -6.56673587,\n       -6.55618738, -6.58263813, -6.59759106, -6.62323799, -6.60574565,\n       -6.60948086, -6.61229932, -6.61602489, -6.64352393, -6.64492704,\n       -6.63830164, -6.62538523, -6.62773945, -6.66691257, -6.65261558,\n       -6.66380831, -6.66725532, -6.66514802, -6.6388137 , -6.66013809,\n       -6.65131096, -6.64865323, -6.64843859, -6.66453943, -6.65139525,\n       -6.66665071, -6.65694915, -6.65781379, -6.64491259, -6.64414746,\n       -6.64625003, -6.64625099, -6.64761692, -6.63896814, -6.64898876,\n       -6.65836137, -6.65344548, -6.65803273, -6.6559006 , -6.6573963 ,\n       -6.65696213, -6.65866507, -6.65473171, -6.64281877, -6.64690239,\n       -6.64958462, -6.64745505, -6.65406146, -6.64683628, -6.65005272,\n       -6.64654234, -6.6459762 , -6.64407586, -6.64050893, -6.64014744,\n       -6.64167562, -6.64430823, -6.64419944, -6.64476765, -6.64242197,\n       -6.64432206, -6.64248166, -6.64532249, -6.64664521, -6.64901451,\n       -6.65402235, -6.65097826, -6.65484143, -6.65132977, -6.65458875,\n       -6.64775126, -6.64588444, -6.64514028, -6.64164671, -6.63949783,\n       -6.64488758, -6.64337246, -6.63421381, -6.63795906, -6.63931009,\n       -6.6405671 , -6.64329144, -6.63988957, -6.6393228 , -6.6354727 ,\n       -6.63383634, -6.62745009, -6.6314359 , -6.63061478, -6.63110039,\n       -6.63149752, -6.62953991, -6.62591886, -6.62832253, -6.63220043])"
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "-1.0 * np.array(cv_result['rmse-mean'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "-6.55618737764928"
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "(-1.0 * np.array(cv_result['rmse-mean'])).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lgb_eval(num_leaves, feature_fraction, max_depth , min_split_gain, min_child_weight):\n",
    "    params = {\n",
    "            \"objective\" : \"regression\", \"bagging_fraction\" : 0.8, \"bagging_freq\": 1,\n",
    "            \"min_child_samples\": 20, \"reg_alpha\": 1, \"reg_lambda\": 1,\"boosting\": \"rf\",\n",
    "            \"learning_rate\" : 0.01, \"subsample\" : 0.8, \"colsample_bytree\" : 0.8, \"verbosity\": -1, \"metric\" : 'rmse'\n",
    "        }\n",
    "    params['feature_fraction'] = max(min(feature_fraction, 1), 0)\n",
    "    params['max_depth'] = int(round(max_depth))\n",
    "    params['num_leaves'] = int(round(num_leaves))\n",
    "    params['min_split_gain'] = min_split_gain\n",
    "    params['min_child_weight'] = min_child_weight\n",
    "    cv_result = lgb.cv(params, train_data, nfold=5, seed=0, verbose_eval =200,stratified=False)\n",
    "    return (-1.0 * np.array(cv_result['rmse-mean'])).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbBO = BayesianOptimization(lgb_eval, {'feature_fraction': (0.1, 0.9),\n",
    "                                            'max_depth': (5, 9),\n",
    "                                            'num_leaves' : (200,300),\n",
    "                                            'min_split_gain': (0.001, 0.1),\n",
    "                                            'min_child_weight': (5, 50)}, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "|   iter    |  target   | featur... | max_depth | min_ch... | min_sp... | num_le... |\n-------------------------------------------------------------------------------------\n| \u001b[0m 1       \u001b[0m | \u001b[0m-4.534   \u001b[0m | \u001b[0m 0.5391  \u001b[0m | \u001b[0m 7.861   \u001b[0m | \u001b[0m 32.12   \u001b[0m | \u001b[0m 0.05494 \u001b[0m | \u001b[0m 242.4   \u001b[0m |\n| \u001b[95m 2       \u001b[0m | \u001b[95m-4.49    \u001b[0m | \u001b[95m 0.6167  \u001b[0m | \u001b[95m 6.75    \u001b[0m | \u001b[95m 45.13   \u001b[0m | \u001b[95m 0.0964  \u001b[0m | \u001b[95m 238.3   \u001b[0m |\n| \u001b[95m 3       \u001b[0m | \u001b[95m-4.487   \u001b[0m | \u001b[95m 0.7334  \u001b[0m | \u001b[95m 7.116   \u001b[0m | \u001b[95m 30.56   \u001b[0m | \u001b[95m 0.09263 \u001b[0m | \u001b[95m 207.1   \u001b[0m |\n| \u001b[0m 4       \u001b[0m | \u001b[0m-5.099   \u001b[0m | \u001b[0m 0.1697  \u001b[0m | \u001b[0m 5.081   \u001b[0m | \u001b[0m 42.47   \u001b[0m | \u001b[0m 0.07804 \u001b[0m | \u001b[0m 287.0   \u001b[0m |\n| \u001b[0m 5       \u001b[0m | \u001b[0m-4.504   \u001b[0m | \u001b[0m 0.8829  \u001b[0m | \u001b[0m 8.197   \u001b[0m | \u001b[0m 25.77   \u001b[0m | \u001b[0m 0.07827 \u001b[0m | \u001b[0m 211.8   \u001b[0m |\n| \u001b[0m 6       \u001b[0m | \u001b[0m-5.499   \u001b[0m | \u001b[0m 0.1     \u001b[0m | \u001b[0m 9.0     \u001b[0m | \u001b[0m 50.0    \u001b[0m | \u001b[0m 0.001   \u001b[0m | \u001b[0m 209.7   \u001b[0m |\n| \u001b[0m 7       \u001b[0m | \u001b[0m-4.608   \u001b[0m | \u001b[0m 0.3836  \u001b[0m | \u001b[0m 6.472   \u001b[0m | \u001b[0m 5.099   \u001b[0m | \u001b[0m 0.04567 \u001b[0m | \u001b[0m 200.1   \u001b[0m |\n| \u001b[0m 8       \u001b[0m | \u001b[0m-4.506   \u001b[0m | \u001b[0m 0.9     \u001b[0m | \u001b[0m 9.0     \u001b[0m | \u001b[0m 5.0     \u001b[0m | \u001b[0m 0.001   \u001b[0m | \u001b[0m 300.0   \u001b[0m |\n| \u001b[0m 9       \u001b[0m | \u001b[0m-4.517   \u001b[0m | \u001b[0m 0.9     \u001b[0m | \u001b[0m 5.0     \u001b[0m | \u001b[0m 5.0     \u001b[0m | \u001b[0m 0.1     \u001b[0m | \u001b[0m 267.6   \u001b[0m |\n| \u001b[0m 10      \u001b[0m | \u001b[0m-4.517   \u001b[0m | \u001b[0m 0.9     \u001b[0m | \u001b[0m 5.0     \u001b[0m | \u001b[0m 23.03   \u001b[0m | \u001b[0m 0.1     \u001b[0m | \u001b[0m 200.0   \u001b[0m |\n=====================================================================================\n"
    }
   ],
   "source": [
    "lgbBO.maximize(init_points=5, n_iter=5,acq='ei')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "|   iter    |  target   | featur... | max_depth | min_ch... | min_sp... | num_le... |\n-------------------------------------------------------------------------------------\n| \u001b[0m 1       \u001b[0m | \u001b[0m-4.534   \u001b[0m | \u001b[0m 0.5391  \u001b[0m | \u001b[0m 7.861   \u001b[0m | \u001b[0m 32.12   \u001b[0m | \u001b[0m 0.05494 \u001b[0m | \u001b[0m 242.4   \u001b[0m |\n| \u001b[95m 2       \u001b[0m | \u001b[95m-4.49    \u001b[0m | \u001b[95m 0.6167  \u001b[0m | \u001b[95m 6.75    \u001b[0m | \u001b[95m 45.13   \u001b[0m | \u001b[95m 0.0964  \u001b[0m | \u001b[95m 238.3   \u001b[0m |\n| \u001b[95m 3       \u001b[0m | \u001b[95m-4.487   \u001b[0m | \u001b[95m 0.7334  \u001b[0m | \u001b[95m 7.116   \u001b[0m | \u001b[95m 30.56   \u001b[0m | \u001b[95m 0.09263 \u001b[0m | \u001b[95m 207.1   \u001b[0m |\n| \u001b[0m 4       \u001b[0m | \u001b[0m-5.099   \u001b[0m | \u001b[0m 0.1697  \u001b[0m | \u001b[0m 5.081   \u001b[0m | \u001b[0m 42.47   \u001b[0m | \u001b[0m 0.07804 \u001b[0m | \u001b[0m 287.0   \u001b[0m |\n| \u001b[0m 5       \u001b[0m | \u001b[0m-4.504   \u001b[0m | \u001b[0m 0.8829  \u001b[0m | \u001b[0m 8.197   \u001b[0m | \u001b[0m 25.77   \u001b[0m | \u001b[0m 0.07827 \u001b[0m | \u001b[0m 211.8   \u001b[0m |\n| \u001b[0m 6       \u001b[0m | \u001b[0m-4.5     \u001b[0m | \u001b[0m 0.6119  \u001b[0m | \u001b[0m 5.573   \u001b[0m | \u001b[0m 47.51   \u001b[0m | \u001b[0m 0.05266 \u001b[0m | \u001b[0m 241.5   \u001b[0m |\n| \u001b[0m 7       \u001b[0m | \u001b[0m-4.629   \u001b[0m | \u001b[0m 0.3116  \u001b[0m | \u001b[0m 8.097   \u001b[0m | \u001b[0m 25.53   \u001b[0m | \u001b[0m 0.05727 \u001b[0m | \u001b[0m 201.9   \u001b[0m |\n| \u001b[0m 8       \u001b[0m | \u001b[0m-4.499   \u001b[0m | \u001b[0m 0.5941  \u001b[0m | \u001b[0m 7.448   \u001b[0m | \u001b[0m 32.76   \u001b[0m | \u001b[0m 0.09443 \u001b[0m | \u001b[0m 268.2   \u001b[0m |\n| \u001b[0m 9       \u001b[0m | \u001b[0m-4.602   \u001b[0m | \u001b[0m 0.3876  \u001b[0m | \u001b[0m 6.748   \u001b[0m | \u001b[0m 36.39   \u001b[0m | \u001b[0m 0.006962\u001b[0m | \u001b[0m 266.7   \u001b[0m |\n| \u001b[0m 10      \u001b[0m | \u001b[0m-4.491   \u001b[0m | \u001b[0m 0.6365  \u001b[0m | \u001b[0m 5.842   \u001b[0m | \u001b[0m 10.8    \u001b[0m | \u001b[0m 0.03223 \u001b[0m | \u001b[0m 236.4   \u001b[0m |\n| \u001b[0m 11      \u001b[0m | \u001b[0m-4.506   \u001b[0m | \u001b[0m 0.9     \u001b[0m | \u001b[0m 9.0     \u001b[0m | \u001b[0m 5.0     \u001b[0m | \u001b[0m 0.1     \u001b[0m | \u001b[0m 276.1   \u001b[0m |\n| \u001b[0m 12      \u001b[0m | \u001b[0m-4.517   \u001b[0m | \u001b[0m 0.9     \u001b[0m | \u001b[0m 5.0     \u001b[0m | \u001b[0m 50.0    \u001b[0m | \u001b[0m 0.1     \u001b[0m | \u001b[0m 212.5   \u001b[0m |\n| \u001b[0m 13      \u001b[0m | \u001b[0m-4.506   \u001b[0m | \u001b[0m 0.9     \u001b[0m | \u001b[0m 9.0     \u001b[0m | \u001b[0m 19.01   \u001b[0m | \u001b[0m 0.1     \u001b[0m | \u001b[0m 266.1   \u001b[0m |\n| \u001b[0m 14      \u001b[0m | \u001b[0m-4.506   \u001b[0m | \u001b[0m 0.9     \u001b[0m | \u001b[0m 9.0     \u001b[0m | \u001b[0m 5.0     \u001b[0m | \u001b[0m 0.1     \u001b[0m | \u001b[0m 300.0   \u001b[0m |\n| \u001b[0m 15      \u001b[0m | \u001b[0m-4.517   \u001b[0m | \u001b[0m 0.9     \u001b[0m | \u001b[0m 5.0     \u001b[0m | \u001b[0m 19.45   \u001b[0m | \u001b[0m 0.1     \u001b[0m | \u001b[0m 279.5   \u001b[0m |\n| \u001b[0m 16      \u001b[0m | \u001b[0m-4.517   \u001b[0m | \u001b[0m 0.9     \u001b[0m | \u001b[0m 5.0     \u001b[0m | \u001b[0m 34.05   \u001b[0m | \u001b[0m 0.1     \u001b[0m | \u001b[0m 218.7   \u001b[0m |\n| \u001b[0m 17      \u001b[0m | \u001b[0m-4.506   \u001b[0m | \u001b[0m 0.9     \u001b[0m | \u001b[0m 9.0     \u001b[0m | \u001b[0m 50.0    \u001b[0m | \u001b[0m 0.1     \u001b[0m | \u001b[0m 200.0   \u001b[0m |\n| \u001b[0m 18      \u001b[0m | \u001b[0m-4.506   \u001b[0m | \u001b[0m 0.9     \u001b[0m | \u001b[0m 9.0     \u001b[0m | \u001b[0m 26.67   \u001b[0m | \u001b[0m 0.1     \u001b[0m | \u001b[0m 271.4   \u001b[0m |\n| \u001b[0m 19      \u001b[0m | \u001b[0m-4.517   \u001b[0m | \u001b[0m 0.9     \u001b[0m | \u001b[0m 5.0     \u001b[0m | \u001b[0m 25.92   \u001b[0m | \u001b[0m 0.1     \u001b[0m | \u001b[0m 263.3   \u001b[0m |\n| \u001b[0m 20      \u001b[0m | \u001b[0m-5.499   \u001b[0m | \u001b[0m 0.1     \u001b[0m | \u001b[0m 9.0     \u001b[0m | \u001b[0m 5.0     \u001b[0m | \u001b[0m 0.1     \u001b[0m | \u001b[0m 249.8   \u001b[0m |\n=====================================================================================\n"
    }
   ],
   "source": [
    "def bayes_parameter_opt_lgb(X, y, init_round=15, opt_round=25, n_folds=5, random_seed=0, n_estimators=10000, learning_rate=0.05, output_process=False):\n",
    "    # prepare data\n",
    "    train_data = lgb.Dataset(data=X, label=y, categorical_feature = list(X.columns),free_raw_data=False)\n",
    "    # parameters\n",
    "\n",
    "    def lgb_eval(num_leaves, feature_fraction, max_depth , min_split_gain, min_child_weight):\n",
    "        params = {\n",
    "            \"objective\" : \"regression\", \"bagging_fraction\" : 0.8, \"bagging_freq\": 1,\n",
    "            \"min_child_samples\": 20, \"reg_alpha\": 1, \"reg_lambda\": 1,\"boosting\": \"rf\",\n",
    "            \"learning_rate\" : 0.01, \"subsample\" : 0.8, \"colsample_bytree\" : 0.8, \"verbosity\": -1, \"metric\" : 'rmse'\n",
    "        }\n",
    "        params['feature_fraction'] = max(min(feature_fraction, 1), 0)\n",
    "        params['max_depth'] = int(round(max_depth))\n",
    "        params['num_leaves'] = int(round(num_leaves))\n",
    "        params['min_split_gain'] = min_split_gain\n",
    "        params['min_child_weight'] = min_child_weight\n",
    "\n",
    "        cv_result = lgb.cv(params, train_data, nfold=n_folds, seed=random_seed, verbose_eval =200,stratified=False)\n",
    "        return (-1.0 * np.array(cv_result['rmse-mean'])).max()\n",
    "    \n",
    "        # range \n",
    "    lgbBO = BayesianOptimization(lgb_eval, {'feature_fraction': (0.1, 0.9),\n",
    "                                            'max_depth': (5, 9),\n",
    "                                            'num_leaves' : (200,300),\n",
    "                                            'min_split_gain': (0.001, 0.1),\n",
    "                                            'min_child_weight': (5, 50)}, random_state=0)\n",
    "        # optimize\n",
    "    lgbBO.maximize(init_points=init_round, n_iter=opt_round,acq='ei')\n",
    "\n",
    "        # output optimization process\n",
    "    if output_process==True: lgbBO.points_to_csv(\"bayes_opt_result.csv\")\n",
    "\n",
    "        # return best parameters\n",
    "    # return lgbBO.res['max']['max_params']\n",
    "    return lgbBO\n",
    "\n",
    "opt_params = bayes_parameter_opt_lgb(X, y, init_round=10, opt_round=10, n_folds=5, random_seed=0, n_estimators=1000, learning_rate=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "{'feature_fraction': 0.7333800304661316,\n 'max_depth': 7.115579679011618,\n 'min_child_weight': 30.562005249226953,\n 'min_split_gain': 0.09263406719097345,\n 'num_leaves': 207.1036058197887}"
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "source": [
    "opt_params.max['params']\n",
    "# opt_params.res['max']['max_params']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_params = {\n",
    "    'feature_fraction': 0.7333800304661316,\n",
    "    'max_depth': 7,\n",
    "    'min_child_weight': 30.562005249226953,\n",
    "    'min_split_gain': 0.09263406719097345,\n",
    "    'num_leaves': 207\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_val, y_train, y_val = train_test_split(X, y, random_state=0)\n",
    "\n",
    "\n",
    "clf = lgb.train(lgb_params, trn_data, num_round, valid_sets = [trn_data, val_data], verbose_eval=1000, early_stopping_rounds = 100)\n",
    "# model.fit(x_train, y_train, eval_set=[(x_val, y_val)], early_stopping_rounds=100, verbose=False)"
   ]
  }
 ]
}