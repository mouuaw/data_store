{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.3-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python37364bitbaseconda3e8d1efd23e942ffb39a1c2f774bdc3f",
   "display_name": "Python 3.7.3 64-bit ('base': conda)"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.stats import chi2_contingency\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "def get_model_cv_prediction(model, X_data, y_target):\n",
    "    neg_mse_scores = cross_val_score(model, X_data, y_target, scoring=\"neg_mean_squared_error\", cv = 5)\n",
    "    rmse_scores = np.sqrt(-1 * neg_mse_scores)\n",
    "    avg_rmse = np.mean(rmse_scores)\n",
    "    print('##### ', model.__class__.__name__, ' #####')\n",
    "    print(' 5 교차 검증의 평균 RMSE : {0:.3f} '.format(avg_rmse))\n",
    "\n",
    "def get_stacking_base_datasets(model, X_train_n, y_train_n, X_test_n, n_folds):\n",
    "    kf = KFold(n_splits=n_folds, shuffle=False, random_state=0)\n",
    "    train_fold_pred = np.zeros((X_train_n.shape[0], 1))\n",
    "    test_pred = np.zeros((X_test_n.shape[0], n_folds))\n",
    "    # print(model.__class__.__name__, ' model 시작 ')\n",
    "\n",
    "    for folder_counter, (train_index, valid_index) in enumerate(kf.split(X_train_n)):\n",
    "        # print('\\t 폴드 세트: ', folder_counter, ' 시작 ')\n",
    "        X_tr = X_train_n[train_index]\n",
    "        y_tr = y_train_n[train_index]\n",
    "        X_te = X_train_n[valid_index]\n",
    "\n",
    "        model.fit(X_tr, y_tr)\n",
    "\n",
    "        train_fold_pred[valid_index, :] = model.predict(X_te).reshape(-1, 1)\n",
    "        test_pred[:, folder_counter] = model.predict(X_test_n)\n",
    "\n",
    "    test_pred_mean = np.mean(test_pred, axis=1).reshape(-1, 1)\n",
    "\n",
    "    return train_fold_pred, test_pred_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('../data/train.csv', index_col='id')\n",
    "test = pd.read_csv('../data/test.csv', index_col='id')\n",
    "submission = pd.read_csv('../data/sample_submission.csv', index_col='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_upper = train[train['Y18'].isnull()]\n",
    "train_upper = train_upper.drop(['X04', 'X14', 'X16', 'X19', 'X36', 'Y18'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "Index(['X00', 'X01', 'X02', 'X03', 'X05', 'X06', 'X07', 'X08', 'X09', 'X10',\n       'X11', 'X12', 'X13', 'X15', 'X17', 'X18', 'X20', 'X21', 'X22', 'X23',\n       'X24', 'X25', 'X26', 'X27', 'X28', 'X29', 'X30', 'X31', 'X32', 'X33',\n       'X34', 'X35', 'X37', 'X38', 'X39', 'Y00', 'Y01', 'Y02', 'Y03', 'Y04',\n       'Y05', 'Y06', 'Y07', 'Y08', 'Y09', 'Y10', 'Y11', 'Y12', 'Y13', 'Y14',\n       'Y15', 'Y16', 'Y17'],\n      dtype='object')"
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "train_upper.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "xgbr = XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
    "             colsample_bynode=1, colsample_bytree=0.7, gamma=0,\n",
    "             importance_type='gain', learning_rate=0.1, max_delta_step=0,\n",
    "             max_depth=3, min_child_weight=1, missing=None, n_estimators=1500,\n",
    "             n_jobs=1, nthread=None, objective='reg:linear', random_state=0,\n",
    "             reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
    "             silent=None, subsample=1, verbosity=1)\n",
    "\n",
    "lgbmr = LGBMRegressor(colsample_bylevel= 0.5, colsample_bytree= 0.7, max_depth= 3, n_estimators= 1500)\n",
    "\n",
    "lasso_reg = Lasso(alpha= 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def three_model_auto(X_train_n, X_test_n, y_train_n):\n",
    "    fold = 5\n",
    "    lasso_train, lasso_test = get_stacking_base_datasets(lasso_reg, X_train_n, y_train_n, X_test_n, fold)\n",
    "    xgb_train, xgb_test = get_stacking_base_datasets(xgbr, X_train_n, y_train_n, X_test_n, fold)\n",
    "    lgbm_train, lgbm_test = get_stacking_base_datasets(lgbmr, X_train_n, y_train_n, X_test_n, fold)\n",
    "\n",
    "    Stack_final_X_train = np.concatenate((lasso_train, xgb_train, lgbm_train), axis=1)\n",
    "    Stack_final_X_test = np.concatenate((lasso_test, xgb_test, lgbm_test), axis=1)\n",
    "\n",
    "    return Stack_final_X_train, Stack_final_X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "columnList = train_upper.columns\n",
    "target_var_list = ['Y00', 'Y01', 'Y02', 'Y03', 'Y04', 'Y05', 'Y06', 'Y07', 'Y08', 'Y09', 'Y10', 'Y11', 'Y12', 'Y13', 'Y14', 'Y15', 'Y16', 'Y17']\n",
    "\n",
    "input_var = list(filter(lambda x: target_var_list.count(x) == 0, columnList))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_features = train_upper[input_var]\n",
    "y_target = train_upper['Y00']\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X_features, y_target, test_size=0.3, random_state=0)\n",
    "# print(\"X_train :: \",X_train.head())\n",
    "# print(\"X_test :: \",X_test.head())\n",
    "# print(\"y_train :: \",y_train.head())\n",
    "# print(\"y_test :: \",y_test.head())\n",
    "\n",
    "\n",
    "# print(\"X_features :: \",X_features.head())\n",
    "# print(\"test_input :: \",test[input_var].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "columnList = train_upper.columns\n",
    "y_list = ['Y00', 'Y01', 'Y02', 'Y03', 'Y04', 'Y05', 'Y06', 'Y07', 'Y08', 'Y09', 'Y10', 'Y11', 'Y12', 'Y13', 'Y14', 'Y15', 'Y16', 'Y17']\n",
    "target_var_list = ['Y15', 'Y16']\n",
    "\n",
    "input_var = list(filter(lambda x: y_list.count(x) == 0, columnList))\n",
    "\n",
    "test_input = test.drop(['X04', 'X14', 'X16', 'X19', 'X36'], axis=1)\n",
    "X_features = train_upper[input_var]\n",
    "# X_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "def stack_auto(X_features, X_test, y_target):\n",
    "\n",
    "    X_train_n = X_features.values\n",
    "    X_test_n = X_test.values\n",
    "    y_train_n = y_target.values\n",
    "\n",
    "    Stack_final_X_train, Stack_final_X_test = three_model_auto(X_train_n, X_test_n, y_train_n)\n",
    "\n",
    "    meta_model_lgbmr = LGBMRegressor(colsample_bylevel= 0.5, colsample_bytree= 0.7, max_depth= 3, n_estimators= 1500)\n",
    "\n",
    "    meta_model_lgbmr.fit(Stack_final_X_train, y_target)\n",
    "    final = meta_model_lgbmr.predict(Stack_final_X_train)\n",
    "    mse = mean_squared_error(y_target, final)\n",
    "    rmse = np.sqrt(mse)\n",
    "    print('스태킹 회귀 모델 최종 RMSE :: ',rmse)\n",
    "\n",
    "    return meta_model_lgbmr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Y15\n[18:29:57] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n[18:30:05] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n[18:30:14] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n[18:30:22] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n[18:30:31] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n스태킹 회귀 모델 최종 RMSE ::  1.2604191356174996\n[18:30:53] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n[18:31:01] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n[18:31:10] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n[18:31:18] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n[18:31:27] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\nY16\n[18:31:43] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n[18:31:52] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n[18:32:02] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n[18:32:11] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n[18:32:19] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n스태킹 회귀 모델 최종 RMSE ::  1.437818611401416\n[18:32:42] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n[18:32:51] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n[18:32:59] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n[18:33:08] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n[18:33:17] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
    }
   ],
   "source": [
    "X_features = train_upper[input_var]\n",
    "\n",
    "trainNotNull = train[train['Y18'].notnull()]\n",
    "trainNotNull = trainNotNull.drop(['X04', 'X14', 'X16', 'X19', 'X36'], axis=1)\n",
    "trainNotNull\n",
    "\n",
    "\n",
    "for target_col in target_var_list:\n",
    "    print(target_col)\n",
    "\n",
    "    y_target = train_upper[target_col]\n",
    "    model = stack_auto(X_features, test_input, y_target)\n",
    "\n",
    "    X_train_n = train_upper[input_var].values\n",
    "    X_test_n = trainNotNull[input_var].values\n",
    "    y_train_n = train_upper[target_col].values\n",
    "\n",
    "    final_X_train, final_X_test = three_model_auto(X_train_n, X_test_n, y_train_n)\n",
    "\n",
    "    pred = model.predict(final_X_test)\n",
    "    trainNotNull[target_col] = pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Y15\n[18:34:33] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n[18:34:34] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n[18:34:36] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n[18:34:38] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n[18:34:39] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n스태킹 회귀 모델 최종 RMSE ::  0.6103677216787506\n[18:34:48] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n[18:34:49] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n[18:34:51] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n[18:34:53] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n[18:34:54] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\nY16\n[18:35:03] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n[18:35:05] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n[18:35:06] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n[18:35:08] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n[18:35:10] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n스태킹 회귀 모델 최종 RMSE ::  0.5372330056569986\n[18:35:18] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n[18:35:20] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n[18:35:22] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n[18:35:24] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n[18:35:26] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
    }
   ],
   "source": [
    "# test\n",
    "\n",
    "trainNotNull_X_features = trainNotNull[input_var]\n",
    "\n",
    "for target_col in target_var_list:\n",
    "    print(target_col)\n",
    "    trainNotNull_y_target = trainNotNull[target_col]\n",
    "    model = stack_auto(trainNotNull_X_features, test_input, trainNotNull_y_target)\n",
    "\n",
    "    X_train_n = trainNotNull[input_var].values\n",
    "    X_test_n = test[input_var].values\n",
    "    y_train_n = trainNotNull[target_col].values\n",
    "\n",
    "    final_X_train, final_X_test = three_model_auto(X_train_n, X_test_n, y_train_n)\n",
    "\n",
    "    pred = model.predict(final_X_test)\n",
    "    test[target_col] = pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[18:37:54] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n[18:37:55] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n[18:37:55] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n[18:37:55] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n[18:37:55] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n스태킹 회귀 모델 최종 RMSE ::  1.0377650112415577\n[18:37:56] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n[18:37:57] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n[18:37:58] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n[18:37:58] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n[18:37:59] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([21.09660948, 21.45818682, 21.54536619, ..., 30.21326435,\n       26.48961455, 27.25603648])"
     },
     "metadata": {},
     "execution_count": 20
    }
   ],
   "source": [
    "trainNotNull\n",
    "\n",
    "input_var_y = ['Y15', 'Y16']\n",
    "target_var_y = ['Y18']\n",
    "\n",
    "trainNotNull_features_y = trainNotNull[input_var_y]\n",
    "trainNotNull_y_target = trainNotNull[target_var_y]\n",
    "modelBB = stack_auto(trainNotNull_features_y, trainNotNull_features_y, trainNotNull_y_target)\n",
    "\n",
    "trainNotNull_X_train_n = trainNotNull[input_var_y].values\n",
    "trainNotNull_X_test_n = test[input_var_y].values\n",
    "trainNotNull_y_train_n = trainNotNull[target_var_y].values\n",
    "\n",
    "trainNotNull_final_X_train, trainNotNull_final_X_test = three_model_auto(trainNotNull_X_train_n, trainNotNull_X_test_n, trainNotNull_y_train_n)\n",
    "\n",
    "pred = modelBB.predict(trainNotNull_final_X_test)\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputDf = pd.DataFrame()\n",
    "outputDf['id'] = test.index\n",
    "outputDf['Y18'] = pred\n",
    "outputDf.to_csv('submission.csv', index=False)"
   ]
  }
 ]
}